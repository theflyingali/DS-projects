{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5badca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_colwidth', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e729087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be88d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13164 entries, 0 to 13163\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Release Year      13164 non-null  int64 \n",
      " 1   Title             13164 non-null  object\n",
      " 2   Origin/Ethnicity  13164 non-null  object\n",
      " 3   Director          13164 non-null  object\n",
      " 4   Cast              12980 non-null  object\n",
      " 5   Genre             13164 non-null  object\n",
      " 6   Wiki Page         13164 non-null  object\n",
      " 7   Plot              13164 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 822.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be3e74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1977.190064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.418616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1953.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1983.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Release Year\n",
       "count  13164.000000\n",
       "mean    1977.190064\n",
       "std       28.418616\n",
       "min     1903.000000\n",
       "25%     1953.000000\n",
       "50%     1983.000000\n",
       "75%     2004.000000\n",
       "max     2017.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff46c4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drama        4781\n",
       "comedy       3503\n",
       "horror        937\n",
       "action        890\n",
       "thriller      768\n",
       "romance       743\n",
       "western       678\n",
       "crime         442\n",
       "adventure     422\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee77780b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td>1978</td>\n",
       "      <td>The Stud</td>\n",
       "      <td>British</td>\n",
       "      <td>Quentin Masters</td>\n",
       "      <td>Joan Collins, Oliver Tobias</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Stud_(film)</td>\n",
       "      <td>Fontaine Khaled is the London wife of a wealthy but boring businessman. She spends his money on her nightclub, Hobo,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>1945</td>\n",
       "      <td>Bring on the Girls</td>\n",
       "      <td>American</td>\n",
       "      <td>Sidney Lanfield</td>\n",
       "      <td>Veronica Lake, Marjorie Reynolds</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bring_on_the_Girls_(film)</td>\n",
       "      <td>Wealthy J. Newport Bates breaks off an engagement after discovering his fiancee is a gold digger. He joins the Navy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12880</th>\n",
       "      <td>2013</td>\n",
       "      <td>Mahapurush O Kapurush</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>Aniket Chattopadhyay</td>\n",
       "      <td>Bratya Basu, Dipankar De, Locket Chatterjee, Bhola Tamang, Tanima Sen, Ritwick Chakraborty, Biswanath Basu, Sujoy Pr...</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Mahapurush_O_Kapurush</td>\n",
       "      <td>Bireshwar Chatterjee (Dipankar De), a wealthy industrialist, is a very happy man. The reason for his happiness is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>1944</td>\n",
       "      <td>The Big Noise</td>\n",
       "      <td>American</td>\n",
       "      <td>Malcolm St. Clair</td>\n",
       "      <td>Laurel and Hardy, Doris Merrick</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Big_Noise_(1944_film)</td>\n",
       "      <td>While cleaning the office of a detective agency, janitors Laurel and Hardy answer a telephone call from an inventor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12794</th>\n",
       "      <td>1960</td>\n",
       "      <td>The Savage Innocents</td>\n",
       "      <td>American</td>\n",
       "      <td>Nicholas Ray</td>\n",
       "      <td>Anthony Quinn, Peter O'Toole, Yoko Tani</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Savage_Innocents</td>\n",
       "      <td>Inuk, an Inuk, kills a priest who rejects his traditional offer of food and his wife's company. Pursued by white pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9679</th>\n",
       "      <td>2014</td>\n",
       "      <td>Bhakarkhadi 7 km</td>\n",
       "      <td>Marathi</td>\n",
       "      <td>Umesh Namjoshi</td>\n",
       "      <td>Aniket Vishwasrao, Veena Jamakar, Apurva Nemalekar</td>\n",
       "      <td>drama</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bhakarkhadi_7_km</td>\n",
       "      <td>Bhakharkhadi 7 km tells the story of a young doctor who aspires to a career as a surgeon in America. His dreams are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>1956</td>\n",
       "      <td>The Sharkfighters</td>\n",
       "      <td>American</td>\n",
       "      <td>Jerry Hopper</td>\n",
       "      <td>Victor Mature, Karen Steele</td>\n",
       "      <td>adventure</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Sharkfighters</td>\n",
       "      <td>In August 1943, Lt. Commander Ben Staves (Mature), recovering from the sinking of his destroyer in battle and the lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>1943</td>\n",
       "      <td>The Crystal Ball</td>\n",
       "      <td>American</td>\n",
       "      <td>Elliott Nugent</td>\n",
       "      <td>Paulette Goddard, Ray Milland</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Crystal_Ball_(film)</td>\n",
       "      <td>A maid, in cahoots with Madame Zenobia (Gladys George), a fake psychic, fools Jo Ainsly (Virginia Field) into believ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>1968</td>\n",
       "      <td>All Neat in Black Stockings</td>\n",
       "      <td>British</td>\n",
       "      <td>Christopher Morahan</td>\n",
       "      <td>Victor Henry, Susan George</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/All_Neat_in_Black_Stockings</td>\n",
       "      <td>Ginger (Victor Henry) is a window washer with an eye for the girls. His best friend and neighbor, Dwyer, (Jack Sheph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>2014</td>\n",
       "      <td>Devil's Due</td>\n",
       "      <td>American</td>\n",
       "      <td>Matt Bettinelli-Olpin Tyler Gillett</td>\n",
       "      <td>Zach Gilford\\r\\nAllison Miller\\r\\nSam Anderson\\r\\nAimee Carrero</td>\n",
       "      <td>horror</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Devil%27s_Due_(film)</td>\n",
       "      <td>A young couple, Zach and Samantha McCall, are about to get married when Zach decides he wants to document their life...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Release Year                        Title Origin/Ethnicity  \\\n",
       "6257           1978                     The Stud          British   \n",
       "7903           1945           Bring on the Girls         American   \n",
       "12880          2013        Mahapurush O Kapurush          Bengali   \n",
       "3756           1944                The Big Noise         American   \n",
       "12794          1960         The Savage Innocents         American   \n",
       "9679           2014             Bhakarkhadi 7 km          Marathi   \n",
       "1325           1956            The Sharkfighters         American   \n",
       "2080           1943             The Crystal Ball         American   \n",
       "3325           1968  All Neat in Black Stockings          British   \n",
       "4920           2014                  Devil's Due         American   \n",
       "\n",
       "                                  Director  \\\n",
       "6257                       Quentin Masters   \n",
       "7903                       Sidney Lanfield   \n",
       "12880                 Aniket Chattopadhyay   \n",
       "3756                     Malcolm St. Clair   \n",
       "12794                         Nicholas Ray   \n",
       "9679                        Umesh Namjoshi   \n",
       "1325                          Jerry Hopper   \n",
       "2080                        Elliott Nugent   \n",
       "3325                   Christopher Morahan   \n",
       "4920   Matt Bettinelli-Olpin Tyler Gillett   \n",
       "\n",
       "                                                                                                                          Cast  \\\n",
       "6257                                                                                               Joan Collins, Oliver Tobias   \n",
       "7903                                                                                          Veronica Lake, Marjorie Reynolds   \n",
       "12880  Bratya Basu, Dipankar De, Locket Chatterjee, Bhola Tamang, Tanima Sen, Ritwick Chakraborty, Biswanath Basu, Sujoy Pr...   \n",
       "3756                                                                                           Laurel and Hardy, Doris Merrick   \n",
       "12794                                                                                  Anthony Quinn, Peter O'Toole, Yoko Tani   \n",
       "9679                                                                        Aniket Vishwasrao, Veena Jamakar, Apurva Nemalekar   \n",
       "1325                                                                                               Victor Mature, Karen Steele   \n",
       "2080                                                                                             Paulette Goddard, Ray Milland   \n",
       "3325                                                                                                Victor Henry, Susan George   \n",
       "4920                                                           Zach Gilford\\r\\nAllison Miller\\r\\nSam Anderson\\r\\nAimee Carrero   \n",
       "\n",
       "           Genre                                                  Wiki Page  \\\n",
       "6257       drama              https://en.wikipedia.org/wiki/The_Stud_(film)   \n",
       "7903      comedy    https://en.wikipedia.org/wiki/Bring_on_the_Girls_(film)   \n",
       "12880     comedy        https://en.wikipedia.org/wiki/Mahapurush_O_Kapurush   \n",
       "3756      comedy    https://en.wikipedia.org/wiki/The_Big_Noise_(1944_film)   \n",
       "12794      drama         https://en.wikipedia.org/wiki/The_Savage_Innocents   \n",
       "9679       drama             https://en.wikipedia.org/wiki/Bhakarkhadi_7_km   \n",
       "1325   adventure            https://en.wikipedia.org/wiki/The_Sharkfighters   \n",
       "2080      comedy      https://en.wikipedia.org/wiki/The_Crystal_Ball_(film)   \n",
       "3325      comedy  https://en.wikipedia.org/wiki/All_Neat_in_Black_Stockings   \n",
       "4920      horror         https://en.wikipedia.org/wiki/Devil%27s_Due_(film)   \n",
       "\n",
       "                                                                                                                          Plot  \n",
       "6257   Fontaine Khaled is the London wife of a wealthy but boring businessman. She spends his money on her nightclub, Hobo,...  \n",
       "7903   Wealthy J. Newport Bates breaks off an engagement after discovering his fiancee is a gold digger. He joins the Navy ...  \n",
       "12880  Bireshwar Chatterjee (Dipankar De), a wealthy industrialist, is a very happy man. The reason for his happiness is th...  \n",
       "3756   While cleaning the office of a detective agency, janitors Laurel and Hardy answer a telephone call from an inventor ...  \n",
       "12794  Inuk, an Inuk, kills a priest who rejects his traditional offer of food and his wife's company. Pursued by white pol...  \n",
       "9679   Bhakharkhadi 7 km tells the story of a young doctor who aspires to a career as a surgeon in America. His dreams are ...  \n",
       "1325   In August 1943, Lt. Commander Ben Staves (Mature), recovering from the sinking of his destroyer in battle and the lo...  \n",
       "2080   A maid, in cahoots with Madame Zenobia (Gladys George), a fake psychic, fools Jo Ainsly (Virginia Field) into believ...  \n",
       "3325   Ginger (Victor Henry) is a window washer with an eye for the girls. His best friend and neighbor, Dwyer, (Jack Sheph...  \n",
       "4920   A young couple, Zach and Samantha McCall, are about to get married when Zach decides he wants to document their life...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401213a5",
   "metadata": {},
   "source": [
    "# Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e204350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e7b713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_1 = Pipeline([\n",
    "                     ('vectorizer' , CountVectorizer()),\n",
    "                     ('classifier' , LogisticRegression(max_iter=3000,multi_class='ovr'))\n",
    "                    ])\n",
    "pipeline_2 = Pipeline([\n",
    "                     ('vectorizer' , CountVectorizer()),\n",
    "                     ('classifier' , LogisticRegression(max_iter=3000,multi_class='multinomial'))\n",
    "                    ])\n",
    "\n",
    "parameters = {'vectorizer__max_df' : [.6,.8],\n",
    "              'vectorizer__min_df' : [.01, .02, 0.05],\n",
    "              'vectorizer__ngram_range' : [(1,1), (1,2)],\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c635c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_1 = GridSearchCV(pipeline_1,\n",
    "                           parameters,\n",
    "                           n_jobs = -1,\n",
    "                           cv = 5,\n",
    "                           verbose = 1)\n",
    "\n",
    "grid_search_2 = GridSearchCV(pipeline_2,\n",
    "                           parameters,\n",
    "                           n_jobs = -1,\n",
    "                           cv = 5,\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8daea884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(max_iter=3000,\n",
       "                                                           multi_class='ovr'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__max_df': [0.6, 0.8],\n",
       "                         'vectorizer__min_df': [0.01, 0.02, 0.05],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_1.fit(train_df['Plot'],train_df['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75cf302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(max_iter=3000,\n",
       "                                                           multi_class='multinomial'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__max_df': [0.6, 0.8],\n",
       "                         'vectorizer__min_df': [0.01, 0.02, 0.05],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_2.fit(train_df['Plot'],train_df['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "309c2229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(max_df=0.8, min_df=0.01)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(max_iter=3000, multi_class='ovr'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a341aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 CountVectorizer(max_df=0.8, min_df=0.01, ngram_range=(1, 2))),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(max_iter=3000, multi_class='multinomial'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904c19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions\n",
    "best_pipe_1 = grid_search_1.best_estimator_\n",
    "best_pipe_2 = grid_search_2.best_estimator_\n",
    "\n",
    "lr_prediction_1 = best_pipe_1.predict(test_df['Plot'])\n",
    "lr_prediction_2 = best_pipe_2.predict(test_df['Plot'])\n",
    "\n",
    "lr_1_predictions = pd.DataFrame(lr_prediction_1,columns=['Predicted'])\n",
    "lr_2_predictions = pd.DataFrame(lr_prediction_2,columns=['Predicted'])\n",
    "lr_1_predictions['Id'] = test_df['Id']\n",
    "lr_2_predictions['Id'] = test_df['Id']\n",
    "\n",
    "lr_1_predictions.to_csv(\"lr_1_predictions.csv\",index = False)\n",
    "lr_2_predictions.to_csv(\"lr_2_predictions.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafdd098",
   "metadata": {},
   "source": [
    "# Improved model utilizing stop words, lemmatization and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fea4d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy.cli\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42196fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/62712963/using-spacy-to-lemmatize-a-column-of-parsed-html-text-in-a-pandas-dataframe\n",
    "train_df['lemmatized'] = train_df['Plot'].apply(lambda x: \" \".join([y.lemma_ for y in nlp(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ad8225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to lemmatize to apply on other DFs\n",
    "def lemmatize_plot(df):\n",
    "    df['lemmatized'] = df['Plot'].apply(lambda x: \" \".join([y.lemma_ for y in nlp(x)]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfcefddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list = ['a','now', 'in', 'on', 'to', 'has', 'about',\n",
    "                   'for', 'that', 'by', 'from', 'an' , 'or', 'as']\n",
    "test_df = lemmatize_plot(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d06d026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use tfidfvectorizer as well as incorporating stop word lists and lemmatized text\n",
    "pipeline_1_lemma = Pipeline([\n",
    "                     ('vectorizer' , TfidfVectorizer(stop_words=stop_words_list)),\n",
    "                     ('classifier' , LogisticRegression(max_iter=3000,multi_class='ovr'))\n",
    "                    ])\n",
    "pipeline_2_lemma = Pipeline([\n",
    "                     ('vectorizer' , TfidfVectorizer(stop_words=stop_words_list)),\n",
    "                     ('classifier' , LogisticRegression(max_iter=3000,multi_class='multinomial'))\n",
    "                    ])\n",
    "\n",
    "parameters = {'vectorizer__max_df' : [.6,.8],\n",
    "              'vectorizer__min_df' : [.01, .02, 0.05],\n",
    "              'vectorizer__ngram_range' : [(1,1), (1,2)],\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a748b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_1_lemma = GridSearchCV(pipeline_1_lemma,\n",
    "                           parameters,\n",
    "                           n_jobs = -1,\n",
    "                           cv = 5,\n",
    "                           verbose = 1)\n",
    "\n",
    "grid_search_2_lemma = GridSearchCV(pipeline_2_lemma,\n",
    "                           parameters,\n",
    "                           n_jobs = -1,\n",
    "                           cv = 5,\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1a4d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer',\n",
       "                                        TfidfVectorizer(stop_words=['a', 'now',\n",
       "                                                                    'in', 'on',\n",
       "                                                                    'to', 'has',\n",
       "                                                                    'about',\n",
       "                                                                    'for',\n",
       "                                                                    'that',\n",
       "                                                                    'by',\n",
       "                                                                    'from',\n",
       "                                                                    'an', 'or',\n",
       "                                                                    'as'])),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(max_iter=3000,\n",
       "                                                           multi_class='ovr'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__max_df': [0.6, 0.8],\n",
       "                         'vectorizer__min_df': [0.01, 0.02, 0.05],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_1_lemma.fit(train_df['lemmatized'],train_df['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61cba89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer',\n",
       "                                        TfidfVectorizer(stop_words=['a', 'now',\n",
       "                                                                    'in', 'on',\n",
       "                                                                    'to', 'has',\n",
       "                                                                    'about',\n",
       "                                                                    'for',\n",
       "                                                                    'that',\n",
       "                                                                    'by',\n",
       "                                                                    'from',\n",
       "                                                                    'an', 'or',\n",
       "                                                                    'as'])),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(max_iter=3000,\n",
       "                                                           multi_class='multinomial'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vectorizer__max_df': [0.6, 0.8],\n",
       "                         'vectorizer__min_df': [0.01, 0.02, 0.05],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_2_lemma.fit(train_df['lemmatized'],train_df['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07c3fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe_1_lemma = grid_search_1_lemma.best_estimator_\n",
    "best_pipe_2_lemma = grid_search_2_lemma.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b8a34a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions\n",
    "lr_prediction_1_lemma = best_pipe_1_lemma.predict(test_df['lemmatized'])\n",
    "lr_prediction_2_lemma = best_pipe_2_lemma.predict(test_df['lemmatized'])\n",
    "\n",
    "lr_1_predictions_lemma = pd.DataFrame(lr_prediction_1_lemma,columns=['Predicted'])\n",
    "lr_2_predictions_lemma = pd.DataFrame(lr_prediction_2_lemma,columns=['Predicted'])\n",
    "\n",
    "lr_1_predictions_lemma['Id'] = test_df['Id']\n",
    "lr_2_predictions_lemma['Id'] = test_df['Id']\n",
    "lr_1_predictions_lemma.to_csv(\"lr_1_predictions_lemma.csv\",index = False)\n",
    "lr_2_predictions_lemma.to_csv(\"lr_2_predictions_lemma.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed36e3",
   "metadata": {},
   "source": [
    "# Other Anaylses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08acd4ec",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fdbaa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09cfe81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN lemmatized\n",
    "# redefine parameters for knn (same as before)\n",
    "\n",
    "pipeline_3_lemma = Pipeline([\n",
    "                     ('vectorizer' , TfidfVectorizer(stop_words=stop_words_list)),\n",
    "                     ('classifier' , KNeighborsClassifier())\n",
    "                    ])\n",
    "\n",
    "parameters = {'classifier__n_neighbors' : [15,35,57],\n",
    "              'classifier__weights': ['distance', 'uniform'],\n",
    "              'vectorizer__max_df' : [.6,.8],\n",
    "              'vectorizer__min_df' : [.01,.05],\n",
    "              'vectorizer__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "grid_knn_lemma = GridSearchCV(pipeline_3_lemma, \n",
    "                    parameters, \n",
    "                    cv = 3,\n",
    "                    n_jobs = -1,\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68382c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vectorizer',\n",
       "                                        TfidfVectorizer(stop_words=['a', 'now',\n",
       "                                                                    'in', 'on',\n",
       "                                                                    'to', 'has',\n",
       "                                                                    'about',\n",
       "                                                                    'for',\n",
       "                                                                    'that',\n",
       "                                                                    'by',\n",
       "                                                                    'from',\n",
       "                                                                    'an', 'or',\n",
       "                                                                    'as'])),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__n_neighbors': [15, 35, 57],\n",
       "                         'classifier__weights': ['distance', 'uniform'],\n",
       "                         'vectorizer__max_df': [0.6, 0.8],\n",
       "                         'vectorizer__min_df': [0.01, 0.05],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn_lemma.fit(train_df['lemmatized'],train_df['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38fd3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe_knn_lemma = grid_knn_lemma.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57a111d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_prediction_lemma =  best_pipe_knn_lemma.predict(test_df['lemmatized'])\n",
    "knn_predictions_lemma = pd.DataFrame(knn_prediction_lemma,columns=['Predicted'])\n",
    "knn_predictions_lemma['Id'] = test_df['Id']\n",
    "knn_predictions_lemma.to_csv(\"knn_predictions_lemma.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b221cb0",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "332d51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0b00d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_topicmodel = CountVectorizer(lowercase   = True,\n",
    "                             ngram_range = (1,1),\n",
    "                             max_df      = .80,\n",
    "                             stop_words  = stop_words_list,\n",
    "                             min_df      = .01,\n",
    "                             max_features = None)\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components   = 8,\n",
    "                                      max_iter       = 50,\n",
    "                                      evaluate_every = 5,\n",
    "                                      verbose = 1\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5c8965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_topicmodel.fit(train_df['lemmatized'])\n",
    "review_tf = vectorizer_topicmodel.transform(train_df['lemmatized'])\n",
    "review_testdf = vectorizer_topicmodel.transform(test_df['lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fd6c6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 50\n",
      "iteration: 2 of max_iter: 50\n",
      "iteration: 3 of max_iter: 50\n",
      "iteration: 4 of max_iter: 50\n",
      "iteration: 5 of max_iter: 50, perplexity: 845.5650\n",
      "iteration: 6 of max_iter: 50\n",
      "iteration: 7 of max_iter: 50\n",
      "iteration: 8 of max_iter: 50\n",
      "iteration: 9 of max_iter: 50\n",
      "iteration: 10 of max_iter: 50, perplexity: 831.3062\n",
      "iteration: 11 of max_iter: 50\n",
      "iteration: 12 of max_iter: 50\n",
      "iteration: 13 of max_iter: 50\n",
      "iteration: 14 of max_iter: 50\n",
      "iteration: 15 of max_iter: 50, perplexity: 825.9670\n",
      "iteration: 16 of max_iter: 50\n",
      "iteration: 17 of max_iter: 50\n",
      "iteration: 18 of max_iter: 50\n",
      "iteration: 19 of max_iter: 50\n",
      "iteration: 20 of max_iter: 50, perplexity: 823.5243\n",
      "iteration: 21 of max_iter: 50\n",
      "iteration: 22 of max_iter: 50\n",
      "iteration: 23 of max_iter: 50\n",
      "iteration: 24 of max_iter: 50\n",
      "iteration: 25 of max_iter: 50, perplexity: 822.3248\n",
      "iteration: 26 of max_iter: 50\n",
      "iteration: 27 of max_iter: 50\n",
      "iteration: 28 of max_iter: 50\n",
      "iteration: 29 of max_iter: 50\n",
      "iteration: 30 of max_iter: 50, perplexity: 821.5816\n",
      "iteration: 31 of max_iter: 50\n",
      "iteration: 32 of max_iter: 50\n",
      "iteration: 33 of max_iter: 50\n",
      "iteration: 34 of max_iter: 50\n",
      "iteration: 35 of max_iter: 50, perplexity: 821.1544\n",
      "iteration: 36 of max_iter: 50\n",
      "iteration: 37 of max_iter: 50\n",
      "iteration: 38 of max_iter: 50\n",
      "iteration: 39 of max_iter: 50\n",
      "iteration: 40 of max_iter: 50, perplexity: 820.7661\n",
      "iteration: 41 of max_iter: 50\n",
      "iteration: 42 of max_iter: 50\n",
      "iteration: 43 of max_iter: 50\n",
      "iteration: 44 of max_iter: 50\n",
      "iteration: 45 of max_iter: 50, perplexity: 820.2580\n",
      "iteration: 46 of max_iter: 50\n",
      "iteration: 47 of max_iter: 50\n",
      "iteration: 48 of max_iter: 50\n",
      "iteration: 49 of max_iter: 50\n",
      "iteration: 50 of max_iter: 50, perplexity: 820.0202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(evaluate_every=5, max_iter=50, n_components=8,\n",
       "                          verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.fit(review_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57566889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we use our topics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b470fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_classifier_count = LogisticRegression(solver = 'lbfgs', max_iter= 5000)\n",
    "topics_train = lda_model.transform(review_tf)\n",
    "lr_classifier_count.fit(topics_train, train_df['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abb556f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_test = lda_model.transform(review_testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d5882d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_topic = lr_classifier_count.predict(topics_test)\n",
    "prediction_topic_df = pd.DataFrame(prediction_topic,columns=['Predicted'])\n",
    "prediction_topic_df['Id'] = test_df['Id']\n",
    "prediction_topic_df.to_csv(\"prediction_topicmodelling.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad3870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
